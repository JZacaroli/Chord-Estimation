{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as nnF\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os, glob, csv\n",
    "import numpy as np\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chord vocabulary is defined in this dictionary.\n",
    "#chord_dict = {'N':0, 'X':0, 'C:maj':1, 'C:min':2, 'Db:maj':3, 'C#:maj':3, 'Db:min':4, 'C#:min':4, 'D:maj':5, 'D:min':6,\n",
    "#                      'Eb:maj':7, 'D#:maj':7, 'Eb:min':8, 'D#:min':8, 'E:maj':9, 'Fb:maj':9, 'E:min':10, 'F:maj':11, 'F:min':12,\n",
    "#                      'Gb:maj':13, 'F#:maj':13, 'Gb:min':14, 'F#:min':14, 'G:maj':15, 'G:min':16,\n",
    "#                      'Ab:maj':17, 'G#:maj':17, 'Ab:min':18, 'G#:min':18, 'A:maj':19, 'A:min':20,\n",
    "#                      'Bb:maj':21, 'A#:maj':21, 'Bb:min':22, 'A#:min':22, 'B:maj':23, 'Cb:maj':23, 'B:min':24}\n",
    "#chord_annotations_directory = 'Data/ChordAnnotations/McGill-GroundTruth'\n",
    "#chord_dict['Cb:maj']\n",
    "\n",
    "\n",
    "#chord_dict = {'N':0, 'X':0, 'C:maj':1, 'C:min':2, 'Db:maj':3, 'C#:maj':3, 'Db:min':4, 'C#:min':4, 'D:maj':5, 'D:min':6,\n",
    "#                      'Eb:maj':7, 'D#:maj':7, 'Eb:min':8, 'D#:min':8, 'E:maj':9, 'Fb:maj':9, 'E:min':10, 'F:maj':11, 'F:min':12,\n",
    "#                      'Gb:maj':13, 'F#:maj':13, 'Gb:min':14, 'F#:min':14, 'G:maj':15, 'G:min':16,\n",
    "#                      'Ab:maj':17, 'G#:maj':17, 'Ab:min':18, 'G#:min':18, 'A:maj':19, 'A:min':20,\n",
    "#                      'Bb:maj':21, 'A#:maj':21, 'Bb:min':22, 'A#:min':22, 'B:maj':23, 'Cb:maj':23, 'B:min':24, 'Cb:min':24,\n",
    "#                      'C:maj7':25, 'C:min7':26, 'C:7':27, 'Db:maj7':28, 'C#:maj7':28, 'Db:min7':29, 'C#:min7':29,\n",
    "#                      'Db:7':30, 'C#:7':30, 'D:maj7':31, 'D:min7':32, 'D:7':33, 'Eb:maj7':34, 'D#:maj7':34,\n",
    "#                      'Eb:min7':35, 'D#:min7':35, 'Eb:7':36, 'D#:7':36, 'E:maj7':37, 'Fb:maj7':37, 'E:min7':38,\n",
    "#                      'E:7':39, 'F:maj7':40, 'F:min7':41, 'F:7':42, 'F#:maj7':43, 'Gb:maj7':43, 'F#:min7':44, 'Gb:min7':44,\n",
    "#                      'F#:7':45, 'Gb:7':45, 'G:maj7':46, 'G:min7':47, 'G:7':48, 'Ab:maj7':49, 'G#:maj7':49,\n",
    "#                      'Ab:min7':50, 'G#:min7':50, 'Ab:7':51, 'G#:7':51, 'A:maj7':52, 'A:min7':53, 'A:7':54,\n",
    "#                      'Bb:maj7':55, 'A#:maj7':55, 'Bb:min7':56, 'A#:min7':56, 'Bb:7':57, 'A#:7':57, 'B:maj7':58,\n",
    "#                      'Cb:maj7':59, 'B:min7':59, 'Cb:min7':59, 'B:7':60, 'Cb:7':60}\n",
    "#chord_annotations_directory = 'Data/ChordAnnotations_majmin7/McGill-GroundTruth_majmin7'\n",
    "\n",
    "chord_dict = {'N':0, 'X':0, 'C:maj':1, 'C:min':2, 'Db:maj':3, 'C#:maj':3, 'Db:min':4, 'C#:min':4, 'D:maj':5, 'D:min':6,\n",
    "              'Eb:maj':7, 'D#:maj':7, 'Eb:min':8, 'D#:min':8, 'E:maj':9, 'Fb:maj':9, 'E:min':10, 'F:maj':11, 'F:min':12,\n",
    "              'Gb:maj':13, 'F#:maj':13, 'Gb:min':14, 'F#:min':14, 'G:maj':15, 'G:min':16,\n",
    "              'Ab:maj':17, 'G#:maj':17, 'Ab:min':18, 'G#:min':18, 'A:maj':19, 'A:min':20,\n",
    "              'Bb:maj':21, 'A#:maj':21, 'Bb:min':22, 'A#:min':22, 'B:maj':23, 'Cb:maj':23, 'B:min':24,\n",
    "              'C:maj/3':25, 'C:min/b3':26, 'C:maj/5':27, 'C:min/5':28, 'Db:maj/3':29, 'C#:maj/3':29, 'Db:min/b3':30,\n",
    "              'C#:min/b3':30, 'Db:maj/5':31, 'C#:maj/5':31, 'Db:min/5':32, 'C#:min/5':32, 'D:maj/3':33, 'D:min/b3':34,\n",
    "              'D:maj/5':35, 'D:min/5':36, 'Eb:maj/3':37, 'D#:maj/3':37, 'Eb:min/b3':38, 'D#:min/b3':38,\n",
    "              'Eb:maj/5':39, 'D#:maj/5':39, 'Eb:min/5':40, 'D#:min/5':40, 'E:maj/3':41, 'Fb:maj/3':41, 'E:min/b3':42,\n",
    "              'E:maj/5':43, 'Fb:maj/5':43, 'E:min/5':44, 'F:maj/3':45, 'F:min/b3':46, 'F:maj/5':47, 'F:min/5':48,\n",
    "              'Gb:maj/3':49, 'F#:maj/3':49, 'Gb:min/b3':50, 'F#:min/b3':50, 'Gb:maj/5':51, 'F#:maj/5':51,\n",
    "              'Gb:min/5':52, 'F#:min/5':52, 'G:maj/3':53, 'G:min/b3':54, 'G:maj/5':55, 'G:min/5':56, 'Ab:maj/3':57,\n",
    "              'G#:maj/3':57, 'Ab:min/b3':58, 'G#:min/b3':58, 'Ab:maj/5':59, 'G#:maj/5':59, 'Ab:min/5':60, 'G#:min/5':60,\n",
    "              'A:maj/3':61, 'A:min/b3':62, 'A:maj/5':63, 'A:min/5':64, 'Bb:maj/3':65, 'A#:maj/3':65, 'Bb:min/b3':66,\n",
    "              'A#:min/b3':66, 'Bb:maj/5':67, 'A#:maj/5':67, 'Bb:min/5':68, 'A#:min/5':68, 'B:maj/3':69, 'Cb:maj/3':69,\n",
    "              'B:min/b3':70, 'Cb:min/b3':70, 'B:maj/5':71, 'Cb:maj/5':71, 'B:min/5':72, 'Cb:min/5':72}\n",
    "chord_annotations_directory = 'Data/ChordAnnotations_majmininv/McGill-GroundTruth_majmininv'\n",
    "\n",
    "chord_vocab_size = max(chord_dict.values())+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_size = 50000\n",
    "test_set_size = 10000\n",
    "train_set = np.zeros((train_set_size, 25)) #train set has a certain number of points, and 25 columns for each of the 24 input chroma vals plus 1 output chord symbol\n",
    "test_set = np.zeros((test_set_size, 25))\n",
    "\n",
    "def pickRandomChordFile():\n",
    "    randomFileNumber = randint(0,889)\n",
    "    filesSearched=0\n",
    "    for f in os.scandir(chord_annotations_directory):\n",
    "        if f.name.endswith('.csv'):\n",
    "            if filesSearched == randomFileNumber:\n",
    "                return f\n",
    "            filesSearched += 1\n",
    "\n",
    "#Pick a random datapoint until this value has reached the train set size.\n",
    "num_of_datapoints_picked = 0\n",
    "while num_of_datapoints_picked < train_set_size:\n",
    "    f = pickRandomChordFile()\n",
    "    dataPointsSearched=0\n",
    "    try:\n",
    "        with open(f, 'r') as chord_file:\n",
    "            rdr = csv.reader(chord_file)\n",
    "            #Take it from the middle of the song\n",
    "            randomDataPointNumber = randint(500, 1500)\n",
    "            for row in rdr:\n",
    "                if dataPointsSearched == randomDataPointNumber:\n",
    "                    #row is ['{TimeInstant}\\t{ChordSymbol}']\n",
    "                    #print(row[0].split('\\t'))\n",
    "                    if row[0].split('\\t')[1] == 'X':\n",
    "                        break\n",
    "                    train_set[num_of_datapoints_picked, 24] = chord_dict[row[0].split('\\t')[1]]\n",
    "\n",
    "                    chroma_filepath = 'Data/Chromagrams/McGill-Chromagrams/'+f.name[0:4]+'_bothchroma.csv'\n",
    "                    with open(chroma_filepath, 'r') as chroma_file:\n",
    "                        rdr = csv.reader(chroma_file)\n",
    "                        chordRowsSearched=0\n",
    "                        for row in rdr:\n",
    "                            if chordRowsSearched == dataPointsSearched:\n",
    "                                train_set[num_of_datapoints_picked, 0:24] = row[2:]\n",
    "                                num_of_datapoints_picked += 1\n",
    "                                break\n",
    "                            chordRowsSearched += 1\n",
    "                #print('Datapointssearched:', dataPointsSearched)\n",
    "                dataPointsSearched += 1\n",
    "    except:\n",
    "        print('Error occurred reading file:', f.name)\n",
    "\n",
    "num_of_datapoints_picked=0\n",
    "#Do the same for the test set.\n",
    "while num_of_datapoints_picked <test_set_size:\n",
    "    f = pickRandomChordFile()\n",
    "    dataPointsSearched=0\n",
    "    try:\n",
    "        with open(f, 'r') as chord_file:\n",
    "            rdr = csv.reader(chord_file)\n",
    "            #Take them from the middle of the song\n",
    "            randomDataPointNumber = randint(500, 3000)\n",
    "            for row in rdr:\n",
    "                if dataPointsSearched == randomDataPointNumber:\n",
    "                    if row[0].split('\\t')[1] == 'X':\n",
    "                        break\n",
    "                    #row is ['{TimeInstant}\\t{ChordSymbol}']\n",
    "                    test_set[num_of_datapoints_picked, 24] = chord_dict[row[0].split('\\t')[1]]\n",
    "\n",
    "                    chroma_filepath = 'Data/Chromagrams/McGill-Chromagrams/'+f.name[0:4]+'_bothchroma.csv'\n",
    "                    with open(chroma_filepath, 'r') as chroma_file:\n",
    "                        rdr = csv.reader(chroma_file)\n",
    "                        chordRowsSearched=0\n",
    "                        for row in rdr:\n",
    "                            if chordRowsSearched == dataPointsSearched:\n",
    "                                test_set[num_of_datapoints_picked, 0:24] = row[2:]\n",
    "                                num_of_datapoints_picked += 1\n",
    "                                break\n",
    "                            chordRowsSearched += 1\n",
    "                dataPointsSearched += 1\n",
    "    except:\n",
    "        print(\"Error occurred reading file\", f.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 25)\n",
      "(10000, 25)\n"
     ]
    }
   ],
   "source": [
    "print(train_set.shape)\n",
    "print(test_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChordDataset(Dataset):\n",
    "    def __init__(self, chordData):\n",
    "        self.labels = chordData[:,24]\n",
    "        self.chromas = chordData[:,0:24]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        sample = {\n",
    "            'chromas': self.chromas[index,:],\n",
    "            'label': self.labels[index]\n",
    "        }\n",
    "        return sample\n",
    "\n",
    "train_dataset = ChordDataset(train_set)\n",
    "test_dataset = ChordDataset(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=64\n",
    "train_loader = DataLoader(dataset=train_dataset,\n",
    "                          batch_size=BATCH_SIZE\n",
    ")\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    #Simple chord estimator. 24 chroma inputs. chord_vocab_size number of outputs.\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        #1 time step net\n",
    "        self.fc1 = nn.Linear(24, chord_vocab_size)\n",
    "        #self.fc2 = nn.Linear(12, chord_vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = nnF.relu(self.fc1(x))\n",
    "        #x = nnF.relu(self.fc2(x))\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_acc(y_pred, y_test):\n",
    "    y_pred_softmax = torch.log_softmax(y_pred, dim = 1)\n",
    "    _, y_pred_tags = torch.max(y_pred_softmax, dim = 1)    \n",
    "    \n",
    "    correct_pred = (y_pred_tags == y_test).float()\n",
    "    acc = correct_pred.sum() / len(correct_pred)\n",
    "    \n",
    "    acc = torch.round(acc) * 100\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_stats = {\n",
    "    'train': [],\n",
    "    \"test\": []\n",
    "}\n",
    "loss_stats = {\n",
    "    'train': [],\n",
    "    \"test\": []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()\n",
    "net.double()\n",
    "cpuDevice = torch.device('cpu')\n",
    "device = torch.device('cuda:0')\n",
    "net.to(device)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning Training...\n",
      "[['Ab:maj', 'Ab:maj'], ['A:maj', 'A:maj'], ['C:maj', 'F:maj'], ['F:maj', 'F:maj'], ['E:maj', 'B:maj'], ['D:maj', 'D:maj'], ['E:maj', 'Bb:maj/5'], ['G:maj', 'G:maj/3'], ['E:maj', 'D:min/5'], ['D:maj', 'D:maj'], ['D:maj', 'D:maj'], ['C:maj', 'C:maj'], ['E:maj', 'E:maj'], ['F:min', 'F:min'], ['G:maj', 'N'], ['D:maj', 'C:maj'], ['A:maj', 'A:maj'], ['G:maj', 'D:maj'], ['D:maj', 'D:maj'], ['F:maj', 'F:maj'], ['E:min', 'G:maj'], ['C:maj', 'A:min/b3'], ['Ab:maj', 'Bb:min'], ['G:maj', 'G:maj'], ['D:maj', 'G:min'], ['A:maj', 'Eb:maj'], ['G:maj', 'G:maj'], ['G:maj', 'G:maj'], ['G:maj', 'N'], ['E:maj', 'E:maj'], ['E:min', 'E:maj'], ['C:maj', 'G:maj'], ['Bb:maj', 'Bb:maj'], ['D:maj', 'E:maj'], ['Db:maj', 'Ab:maj'], ['Eb:maj', 'D:maj'], ['Ab:maj', 'Ab:maj'], ['Ab:maj', 'Ab:min'], ['Ab:maj', 'Ab:maj'], ['Db:maj', 'Db:maj'], ['Bb:maj', 'Bb:maj'], ['F:maj', 'F:maj'], ['Eb:maj', 'F:maj'], ['B:maj', 'B:maj'], ['G:maj', 'G:maj'], ['A:maj', 'B:min'], ['D:maj', 'D:maj'], ['C:maj', 'C:maj'], ['E:min', 'E:min'], ['C:maj', 'C:maj'], ['D:maj', 'D:maj'], ['C:maj', 'C:maj'], ['F:maj', 'F:maj'], ['Ab:maj', 'Ab:maj'], ['E:maj', 'E:maj'], ['Db:maj', 'Db:maj'], ['Bb:maj', 'Bb:maj'], ['E:maj', 'G:maj'], ['G:maj', 'G:maj'], ['C:maj', 'C:maj/3'], ['A:maj', 'D:maj'], ['F:maj', 'C:maj'], ['E:maj', 'Eb:maj'], ['G:maj', 'N']]\n",
      "Epoch 000: | Train Loss: 1.76259 | Test Loss: 1.82115 | Train Acc: 84.026| Test Acc: 78.125\n",
      "[['Ab:maj', 'Ab:maj'], ['A:maj', 'A:maj'], ['C:maj', 'F:maj'], ['F:maj', 'F:maj'], ['E:maj', 'B:maj'], ['D:maj', 'D:maj'], ['E:maj', 'Bb:maj/5'], ['G:maj', 'G:maj/3'], ['E:maj', 'D:min/5'], ['D:maj', 'D:maj'], ['D:maj', 'D:maj'], ['C:maj', 'C:maj'], ['E:maj', 'E:maj'], ['F:min', 'F:min'], ['G:maj', 'N'], ['D:maj', 'C:maj'], ['A:maj', 'A:maj'], ['G:maj', 'D:maj'], ['D:maj', 'D:maj'], ['F:maj', 'F:maj'], ['E:min', 'G:maj'], ['C:maj', 'A:min/b3'], ['Ab:maj', 'Bb:min'], ['G:maj', 'G:maj'], ['D:maj', 'G:min'], ['A:maj', 'Eb:maj'], ['G:maj', 'G:maj'], ['G:maj', 'G:maj'], ['G:maj', 'N'], ['E:maj', 'E:maj'], ['E:min', 'E:maj'], ['C:maj', 'G:maj'], ['Bb:maj', 'Bb:maj'], ['D:maj', 'E:maj'], ['Db:maj', 'Ab:maj'], ['Eb:maj', 'D:maj'], ['Ab:maj', 'Ab:maj'], ['Ab:maj', 'Ab:min'], ['Ab:maj', 'Ab:maj'], ['Db:maj', 'Db:maj'], ['Bb:maj', 'Bb:maj'], ['F:maj', 'F:maj'], ['Eb:maj', 'F:maj'], ['B:maj', 'B:maj'], ['G:maj', 'G:maj'], ['A:maj', 'B:min'], ['D:maj', 'D:maj'], ['C:maj', 'C:maj'], ['E:min', 'E:min'], ['C:maj', 'C:maj'], ['D:maj', 'D:maj'], ['C:maj', 'C:maj'], ['F:maj', 'F:maj'], ['Ab:maj', 'Ab:maj'], ['E:maj', 'E:maj'], ['Db:maj', 'Db:maj'], ['Bb:maj', 'Bb:maj'], ['E:maj', 'G:maj'], ['G:maj', 'G:maj'], ['C:maj', 'C:maj/3'], ['A:maj', 'D:maj'], ['F:maj', 'C:maj'], ['E:maj', 'Eb:maj'], ['G:maj', 'N']]\n",
      "Epoch 001: | Train Loss: 1.71117 | Test Loss: 1.73096 | Train Acc: 85.623| Test Acc: 84.375\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-256-d2c0cb8f244d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m#Add the loss and accuracy for each epoch. Will need to divide by the length of the _loader afterwards.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv_ecs7013P/lib/python3.6/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     94\u001b[0m                 \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m                 \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m                 \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m                     \u001b[0;31m# Maintains the maximum of all 2nd moment running avg. till now\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_of_epochs = 100\n",
    "prevNet = -1 #Used when testing the network\n",
    "\n",
    "print('Beginning Training...')\n",
    "\n",
    "for epoch in range(num_of_epochs):\n",
    "    # TRAINING\n",
    "    train_epoch_loss = 0\n",
    "    train_epoch_acc = 0\n",
    "    \n",
    "\n",
    "    net.train()\n",
    "    for train_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        X_train_batch = train_batch['chromas'].double().to(device)\n",
    "        y_train_batch = train_batch['label'].long().to(device)\n",
    "        \n",
    "        y_train_pred = net(X_train_batch)\n",
    "        \n",
    "        train_loss = loss_function(y_train_pred, y_train_batch)\n",
    "        train_acc = multi_acc(y_train_pred, y_train_batch)\n",
    "        \n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        #Add the loss and accuracy for each epoch. Will need to divide by the length of the _loader afterwards.\n",
    "        train_epoch_loss += train_loss.item()\n",
    "        train_epoch_acc += train_acc.item()\n",
    "        \n",
    "    # VALIDATION    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        test_epoch_loss = 0\n",
    "        test_epoch_acc = 0\n",
    "        \n",
    "        net.eval()\n",
    "        for test_batch in test_loader:\n",
    "            #X_val_batch, y_val_batch = X_val_batch.to(device), y_val_batch.to(device)\n",
    "            X_test_batch = test_batch['chromas'].double().to(device)\n",
    "            y_test_batch = test_batch['label'].long().to(device)\n",
    "            \n",
    "            y_test_pred = net(X_test_batch)\n",
    "                \n",
    "                for j,row in enumerate(y_test_pred):\n",
    "                    chordPred = chord_dict_reverse[torch.argmax(row).item()]\n",
    "                    chordActual = chord_dict_reverse[y_test_batch[j].item()]\n",
    "                    test_preds += [[chordPred, chordActual]]\n",
    "                print(test_preds)\n",
    "                #print(y_test_pred.shape)\n",
    "                #print(y_test_batch.shape)\n",
    "                        \n",
    "            test_loss = loss_function(y_test_pred, y_test_batch)\n",
    "            test_acc = multi_acc(y_test_pred, y_test_batch)\n",
    "            \n",
    "            test_epoch_loss += test_loss.item()\n",
    "            test_epoch_acc += test_acc.item()\n",
    "            \n",
    "    loss_stats['train'].append(train_epoch_loss/len(train_loader))\n",
    "    loss_stats['test'].append(test_epoch_loss/len(test_loader))\n",
    "    accuracy_stats['train'].append(train_epoch_acc/len(train_loader))\n",
    "    accuracy_stats['test'].append(test_epoch_acc/len(test_loader))\n",
    "    prevNet = net\n",
    "                              \n",
    "    print(f'Epoch {epoch+0:03}: | Train Loss: {train_epoch_loss/len(train_loader):.5f} | Test Loss: {test_epoch_loss/len(test_loader):.5f} | Train Acc: {train_epoch_acc/len(train_loader):.3f}| Test Acc: {test_epoch_acc/len(test_loader):.3f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test it on Chopin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = prevNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First create a mapping from class number to chord\n",
    "chord_dict_reverse = {0:'N', 1:'C:maj', 2:'C:min', 3:'Db:maj', 4:'Db:min', 5:'D:maj', 6:'D:min', 7:'Eb:maj',\n",
    "                     8:'Eb:min', 9:'E:maj', 10:'E:min', 11:'F:maj', 12:'F:min', 13:'Gb:maj', 14:'Gb:min', 15:'G:maj',\n",
    "                     16:'G:min', 17: 'Ab:maj', 18:'Ab:min', 19:'A:maj', 20:'A:min', 21:'Bb:maj', 22:'Bb:min',\n",
    "                     23:'B:maj', 24:'B:min', 25:'C:maj/3', 26:'C:min/b3', 27:'C:maj/5', 28:'C:min/5', 29:'Db:maj/3',\n",
    "                     30:'Db:min/b3', 31:'Db:maj/5', 32:'Db:min/5', 33:'D:maj/3', 34:'D:min/b3', 35:'D:maj/5',\n",
    "                     36:'D:min/5', 37:'Eb:maj/3', 38:'Eb:min/b3', 39:'Eb:maj/5', 40:'Eb:min/5', 41:'E:maj/3',\n",
    "                     42:'E:min/b3', 43:'E:maj/5', 44:'E:min/5', 45:'F:maj/3', 46:'F:min/b3', 47:'F:maj/5', 48:'F:min/5',\n",
    "                     49:'Gb:maj/3', 50:'Gb:min/b3', 51:'Gb:maj/5', 52:'Gb:min/5', 53:'G:maj/3', 54:'G:min/b3',\n",
    "                     55:'G:maj/5', 56:'G:min/5', 57:'Ab:maj/3', 58:'Ab:min/b3', 59:'Ab:maj/5', 60:'Ab:min/5',\n",
    "                     61:'A:maj/3', 62:'A:min/b3', 63:'A:maj/5', 64:'A:min/5', 65:'Bb:maj/3', 66:'Bb:min/b3',\n",
    "                     67:'Bb:maj/5', 68:'Bb:min/5', 69:'B:maj/3', 70:'B:min/b3', 71:'B:maj/5', 72:'B:min/5'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the intended chopin chroma values.\n",
    "\n",
    "ChromasPerTimeStep = 24\n",
    "NumOfTimeStepsToRead = 250\n",
    "IdxToReadFrom = 271*44100//2048\n",
    "\n",
    "chopinChromas = np.zeros((NumOfTimeStepsToRead, ChromasPerTimeStep))\n",
    "\n",
    "with open('Data/ChopinChromagrams.csv', 'r') as f:\n",
    "    rdr = csv.reader(f)\n",
    "    for idx, row in enumerate(rdr):\n",
    "        if  IdxToReadFrom <= idx < IdxToReadFrom + NumOfTimeStepsToRead:\n",
    "            chopinChromas[idx-IdxToReadFrom,:] = row[1:]\n",
    "            \n",
    "        if idx >= IdxToReadFrom+NumOfTimeStepsToRead:\n",
    "            break\n",
    "\n",
    "chopinChromas = torch.Tensor(chopinChromas).double().to(device)\n",
    "\n",
    "#Input into the net and get them back on the CPU.\n",
    "chopin_predictions = net(chopinChromas).to(cpuDevice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:  0.0 Chord: C:maj\n",
      "Time:  0.0 Chord: F:maj\n",
      "Time:  0.1 Chord: Bb:maj\n",
      "Time:  0.4 Chord: F:maj\n",
      "Time:  0.5 Chord: Bb:maj\n",
      "Time:  0.6 Chord: F:maj\n",
      "Time:  1.3 Chord: G:maj\n",
      "Time:  1.3 Chord: Bb:maj\n",
      "Time:  2.0 Chord: D:maj\n",
      "Time:  2.1 Chord: F:maj\n",
      "Time:  2.5 Chord: Bb:maj\n",
      "Time:  4.4 Chord: E:maj\n",
      "Time:  5.0 Chord: A:maj\n",
      "Time:  7.0 Chord: D:maj\n",
      "Time:  7.4 Chord: C:maj\n",
      "Time:  7.4 Chord: G:min\n",
      "Time:  8.0 Chord: C:maj\n",
      "Time:  8.1 Chord: C:min\n",
      "Time:  8.7 Chord: C:maj\n",
      "Time:  8.8 Chord: Bb:maj\n",
      "Time:  9.6 Chord: F:maj\n",
      "Time: 10.3 Chord: Bb:maj\n"
     ]
    }
   ],
   "source": [
    "#Get output and turn it back into chords.\n",
    "#chopin_predictions = (batch_num, time_step, chord_values)\n",
    "secondsPerTimeStep = 2048/44100\n",
    "\n",
    "timesAndChords = []\n",
    "\n",
    "prevChord = -1\n",
    "\n",
    "predictedChords = []\n",
    "\n",
    "for time_step in range(NumOfTimeStepsToRead):\n",
    "    #print(chopin_predictions[batchnum,time_step])\n",
    "    chordNumber = torch.argmax(chopin_predictions[time_step]).item()\n",
    "    predictedChords += [chordNumber]\n",
    "    #print(maxIdx)\n",
    "    entropy = torch.distributions.Categorical(probs=chopin_predictions[time_step]).entropy().item()\n",
    "    val = torch.max(chopin_predictions[time_step]).item()\n",
    "    chord = chord_dict_reverse[chordNumber]\n",
    "    #print('Time:', time_step*secondsPerTimeStep, 'Chord:', chord, 'Val:', val, 'Entropy:', entropy)\n",
    "    \n",
    "    if chordNumber != prevChord:\n",
    "        timesAndChords += [[time_step*secondsPerTimeStep, chord_dict_reverse[chordNumber]]]\n",
    "    prevChord = chordNumber\n",
    "\n",
    "for time, chord in timesAndChords:\n",
    "    print(\"Time: %4.1f\" % (time), 'Chord:', chord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import medfilt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:  0.0 Chord: C:maj\n",
      "Time:  0.0 Chord: F:maj\n",
      "Time:  1.3 Chord: G:maj\n",
      "Time:  1.3 Chord: Bb:maj\n",
      "Time:  4.4 Chord: E:maj\n",
      "Time:  5.0 Chord: A:maj\n",
      "Time:  7.0 Chord: G:min\n",
      "Time:  7.5 Chord: D:maj\n",
      "Time:  7.9 Chord: C:min\n",
      "Time:  8.8 Chord: Bb:maj\n",
      "Time:  9.6 Chord: F:maj\n",
      "Time: 10.3 Chord: Bb:maj\n"
     ]
    }
   ],
   "source": [
    "#Median filter the chors and display nicely\n",
    "chopin_chord_numbers_filtered = medfilt(predictedChords, kernel_size=25)\n",
    "prevChord = -1\n",
    "filteredTimesAndChords = []\n",
    "for i, chordNumber in enumerate(chopin_chord_numbers_filtered):\n",
    "    if chordNumber != prevChord:\n",
    "        filteredTimesAndChords += [[i*secondsPerTimeStep, chord_dict_reverse[chordNumber]]]\n",
    "    prevChord=chordNumber\n",
    "    \n",
    "for time, chord in filteredTimesAndChords:\n",
    "    print(\"Time: %4.1f\" % (time), 'Chord:', chord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write the chord times to file.\n",
    "import csv\n",
    "with open('ChopinTimesAndChords.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    for time, chord in filteredTimesAndChords:\n",
    "        writer.writerow([time, chord])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
